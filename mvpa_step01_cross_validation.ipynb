{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d3f3b3-c786-423f-807b-eed931c255a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mvpa_base_functions as bf\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed9ae2e-ba99-4472-a89c-66eb296aa13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase = 'cond' # experimental phase, 'cond', 'ext', or 'recall'\n",
    "mask = 'fearnet' # feature to be used, 'fearnet' or 'wholebrain'\n",
    "trial_block = 1 # trial-block id, 1, 2, 3,or 4\n",
    "dtfile = f'./sample_data/discovery_{phase}_{mask}_{trial_block}block.pkl'\n",
    "svfile = f'./sample_results/discovery_{phase}_{mask}_{trial_block}block_accuracy.pkl'\n",
    "D = pickle.load(open(dtfile, 'rb'))\n",
    "csm_data = D['csm_data']\n",
    "csp_data = D['csp_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc6e5ca-6b33-4f9a-b8b9-aec903054b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subj_num, feat_num = csm_data.shape\n",
    "X = np.concatenate((csm_data, csp_data), axis=0)\n",
    "Y = np.concatenate((0*np.ones(subj_num),1*np.ones(subj_num)), axis=0)\n",
    "group = np.concatenate((np.arange(subj_num),np.arange(subj_num)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e9fcaf-12b4-4d70-a710-b88ea695e362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_num = 20\n",
    "param_list = np.logspace(-4, 4, num=param_num, base=10)\n",
    "LR = LogisticRegression(C=1, solver='liblinear')\n",
    "dclf = Pipeline([('scaler', StandardScaler()), ('clf', LR)])\n",
    "param_grid = {'clf__C':param_list}\n",
    "clf = GridSearchCV(dclf, param_grid, n_jobs=10)\n",
    "\n",
    "\n",
    "gperm_num = 10 # repeat cross-validation for multiple times\n",
    "cv_num = 5 # 5-fold cross-validation\n",
    "all_accuracy = np.zeros(gperm_num)\n",
    "\n",
    "# repeat cross-validation \n",
    "for igrp in range(gperm_num):\n",
    "    rgroup = bf.permute_group(group)\n",
    "\n",
    "    # cross-validation\n",
    "    cvg = GroupKFold(n_splits=cv_num) #make sure csp and csm samples from the same participant are both in training/testing set\n",
    "    cv_prob_pred = np.zeros_like(Y)\n",
    "    for tridx, tsidx in cvg.split(X, Y, rgroup):\n",
    "        trX, trY = X[tridx], Y[tridx]\n",
    "        tsX, tsY = X[tsidx], Y[tsidx]\n",
    "        clf.fit(trX, trY)\n",
    "        prob_pred = clf.predict_proba(tsX)\n",
    "        cv_prob_pred[tsidx] = prob_pred[:,1]\n",
    "\n",
    "    sc, sc_vec = bf.force_binary_accuracy(Y, cv_prob_pred)\n",
    "    all_accuracy[igrp] = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c3e0f8-ea48-428f-a771-d384de37abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_num = 10 # permutation test, time-consuming, increase to 1000 for real run\n",
    "cv_num = 5 # 5-fold cross-validation\n",
    "rand_accuracy = np.zeros(rand_num)\n",
    "\n",
    "# repeat cross-validation \n",
    "for ird in range(rand_num):\n",
    "    rY = bf.permute_Y(Y)\n",
    "\n",
    "    # cross-validation\n",
    "    cvg = GroupKFold(n_splits=cv_num) #make sure csp and csm samples from the same participant are both in training/testing set\n",
    "    cv_prob_pred = np.zeros_like(rY)\n",
    "    for tridx, tsidx in cvg.split(X, rY, group):\n",
    "        trX, trY = X[tridx], rY[tridx]\n",
    "        tsX, tsY = X[tsidx], rY[tsidx]\n",
    "        clf.fit(trX, trY)\n",
    "        prob_pred = clf.predict_proba(tsX)\n",
    "        cv_prob_pred[tsidx] = prob_pred[:,1]\n",
    "\n",
    "    sc, sc_vec = bf.force_binary_accuracy(rY, cv_prob_pred)\n",
    "    rand_accuracy[ird] = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7775b991-0c7d-43f0-8b71-21a44a58a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these variables for plotting\n",
    "mvals = np.mean(all_accuracy)\n",
    "evals = np.std(all_accuracy)/np.sqrt(gperm_num)\n",
    "chance_vals = np.percentile(rand_accuracy, 97.5, axis=0)\n",
    "pickle.dump({'chance_vals':chance_vals,\n",
    "             'mvals':mvals,\n",
    "             'evals':evals},\n",
    "              open(svfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f04a4e-b2ca-456b-b21d-350739b9fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gather results from all phases and trial-blocks\n",
    "## run this cell after get results from each phase and trial-block\n",
    "## i.e., when all files f'./sample_results/discovery_{cphs}_{mask}_{tblk}block_accuracy.pkl' are ready\n",
    "\n",
    "# mask = 'fearnet' # feature to be used, 'fearnet' or 'wholebrain'\n",
    "# all_chance_vals = []\n",
    "# all_mvals = []\n",
    "# all_evals = []\n",
    "# for cphs in ['cond', 'ext', 'recall']:\n",
    "#     for tblk in [1,2,3,4]:\n",
    "#         file = f'./sample_results/discovery_{cphs}_{mask}_{tblk}block_accuracy.pkl'\n",
    "#         D = pickle.load(open(file, 'rb'))\n",
    "#         chance_vals = D['chance_vals']\n",
    "#         mvals = D['mvals']\n",
    "#         evals = D['evals']\n",
    "#         all_mvals.append(mvals)\n",
    "#         all_evals.append(evals)\n",
    "#         all_chance_vals.append(chance_vals)\n",
    "# all_mvals = np.array(all_mvals)\n",
    "# all_evals = np.array(all_evals)\n",
    "# all_chance_vals = np.array(all_chance_vals)\n",
    "\n",
    "# if mask=='wholebrain':\n",
    "#     savefile = './results/whole_brain_cross_validation_accuracy.pkl'\n",
    "# elif mask=='fearnet':\n",
    "#     savefile = './results/threat_circuit_cross_validation_accuracy.pkl'\n",
    "# pickle.dump({'all_chance_vals':all_chance_vals,\n",
    "#              'all_mvals':all_mvals,\n",
    "#              'all_evals':all_evals},\n",
    "#              open(savefile, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
