{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad397fa-d980-49d6-8fce-d3bd69199e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mvpa_base_functions as bf\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3d2f80-aeff-4fd3-9528-8d30a1e7bb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase = 'cond'\n",
    "mask = 'fearnet'\n",
    "trial_block = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d525871d-0ae5-4ac3-bf66-97f67966919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtfile = f'./sample_data/discovery_{phase}_{mask}_{trial_block}block.pkl'\n",
    "svfile = f'./sample_results/predict_pattern_{phase}_{mask}_{trial_block}block.pkl'\n",
    "D = pickle.load(open(dtfile, 'rb'))\n",
    "csm_data = D['csm_data']\n",
    "csp_data = D['csp_data']\n",
    "\n",
    "subj_num, feat_num = csm_data.shape\n",
    "\n",
    "\n",
    "param_num = 20\n",
    "param_list = np.logspace(-4, 4, num=param_num, base=10)\n",
    "LR = LogisticRegression(C=1, solver='liblinear')\n",
    "dclf = Pipeline([('scaler', StandardScaler()), ('clf', LR)])\n",
    "param_grid = {'clf__C':param_list}\n",
    "clf = GridSearchCV(dclf, param_grid, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ceeab3-e498-4975-ad8a-13711fa25730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#bootstrap\n",
    "boot_num = 10\n",
    "boot_pred_patterns = np.zeros((boot_num, feat_num))\n",
    "boot_cls_weights = np.zeros((boot_num, feat_num)) \n",
    "for ibt in range(boot_num):\n",
    "    if ibt%10==0:\n",
    "        print(ibt)\n",
    "        \n",
    "    ridx = np.random.choice(subj_num, subj_num)#resampling with replacement\n",
    "    rX = np.concatenate((csm_data[ridx], csp_data[ridx]), axis=0)\n",
    "    rY = np.concatenate((0*np.ones(subj_num),1*np.ones(subj_num)), axis=0)\n",
    "    group = np.concatenate((np.arange(subj_num),np.arange(subj_num)), axis=0)\n",
    "    rclf = clf\n",
    "    rclf.fit(rX, rY, groups=group)\n",
    "    w = rclf.best_estimator_['clf'].coef_\n",
    "    pp = bf.weight_transform(StandardScaler().fit_transform(rX), w)\n",
    "    \n",
    "    boot_cls_weights[ibt] = w.reshape(-1)\n",
    "    boot_pred_patterns[ibt] = pp.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82124c92-3d95-4a3b-9e24-0e1f7a730be0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# permutation\n",
    "perm_num = 10\n",
    "perm_pred_patterns = np.zeros((perm_num, feat_num))\n",
    "perm_cls_weights = np.zeros((perm_num, feat_num)) \n",
    "\n",
    "X = np.concatenate((csm_data, csp_data), axis=0)\n",
    "Y = np.concatenate((0*np.ones(subj_num),1*np.ones(subj_num)), axis=0)\n",
    "group = np.concatenate((np.arange(subj_num),np.arange(subj_num)), axis=0)\n",
    "clf.fit(X, Y, groups=group)\n",
    "best_C = clf.best_params_['clf__C']\n",
    "\n",
    "for iperm in range(perm_num):\n",
    "    if iperm%10==0:\n",
    "        print(iperm)\n",
    "        \n",
    "    rY = bf.permute_Y(Y)\n",
    "    \n",
    "    bLR = LogisticRegression(C=best_C, solver='liblinear')# for permutation, use the best C to save computation time\n",
    "    pclf = Pipeline([('scaler', StandardScaler()), ('clf', bLR)])\n",
    "    pclf.fit(X, rY)\n",
    "    \n",
    "    w = pclf['clf'].coef_\n",
    "    pp = bf.weight_transform(StandardScaler().fit_transform(X), w)\n",
    "    \n",
    "    perm_cls_weights[ibt] = w.reshape(-1)\n",
    "    perm_pred_patterns[ibt] = pp.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0748080-1963-41bb-ae2d-1a17b6179ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_patterns = np.mean(boot_pred_patterns, axis=0)\n",
    "mperm_pattern = np.mean(perm_pred_patterns, axis=0, keepdims=True)\n",
    "eperm_pattern = np.std(perm_pred_patterns, axis=0, keepdims=True)\n",
    "zvals = (pred_patterns - mperm_pattern) / eperm_pattern\n",
    "zvals = zvals.reshape(-1)\n",
    "pvals = stats.norm.sf(np.abs(zvals))*2\n",
    "pvals = pvals.reshape((-1,))\n",
    "H, pvals_fdr, _, _ = multipletests(pvals, alpha=0.05, method='fdr_bh')\n",
    "pickle.dump({'pred_patterns':pred_patterns,\n",
    "             'zvals':zvals,\n",
    "             'pvals':pvals,\n",
    "             'pvals':pvals_fdr},\n",
    "             open(svfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c4628-d978-40f6-8a6e-9ddf9ac6c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## gather results from all phases and trial-blocks\n",
    "# ## run this cell after get results from each phase and trial-block\n",
    "# ## i.e., when all files f'./sample_results/predict_pattern_{phase}_{mask}_{trial_block}block.pkl' are ready\n",
    "\n",
    "# mask = 'fearnet' # feature to be used, 'fearnet' or 'wholebrain'\n",
    "# all_pvals = []\n",
    "# all_pvals_fdr = []\n",
    "# all_zvals = []\n",
    "# all_pred_patterns = []\n",
    "# for cphs in ['cond', 'ext', 'recall']:\n",
    "#     for tblk in [1,2,3,4]:\n",
    "#         if cphs=='ext' and tblk>1:# only for trial-blocks with robust classification performance\n",
    "#             continue\n",
    "#         elif cphs=='recall' and tblk==2:\n",
    "#             continue\n",
    "#         elif cphs=='recall' and tblk==4:\n",
    "#             continue\n",
    "#         file = f'./sample_results/predict_pattern_{phase}_{mask}_{trial_block}block.pkl'\n",
    "#         D = pickle.load(open(file, 'rb'))\n",
    "#         zvals = D['zvals']\n",
    "#         pvals = D['pvals']\n",
    "#         pvals_fdr = D['pvals_fdr']\n",
    "#         pred_patterns = D['pred_patterns']\n",
    "        \n",
    "#         all_zvals.append(zvals)\n",
    "#         all_pvals.append(pvals)\n",
    "#         all_pvals_fdr.append(pvals_fdr)\n",
    "#         all_pred_patterns.append(pred_patterns)\n",
    "# all_zvals = np.stack(all_zvals)\n",
    "# all_pvals = np.stack(all_pvals)\n",
    "# all_pvals_fdr = np.stack(all_pvals_fdr)\n",
    "# all_pred_patterns = np.stack(all_pred_patterns)\n",
    "\n",
    "# if mask=='wholebrain':\n",
    "#     savefile = './sample_results/whole_brain_predictive_patterns.pkl'\n",
    "# elif mask=='fearnet':\n",
    "#     savefile = './sample_results/threat_circuit_predictive_patterns.pkl'\n",
    "    \n",
    "# pickle.dump({'all_zvals':all_zvals,\n",
    "#              'all_pvals':all_pvals,\n",
    "#              'all_pvals_fdr':all_pvals_fdr,\n",
    "#              'all_pred_patterns':all_pred_patterns},\n",
    "#              open(savefile, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
